{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login \n",
    "login(token=\"hidden_token_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 499M/499M [00:31<00:00, 15.7MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uploaded to https://huggingface.co/kai-pn/sentiment-analysis-roberta\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "\n",
    "# Define the repository name and path\n",
    "repo_name = \"sentiment-analysis-roberta\"  # Replace with your desired model name\n",
    "repo_url = HfApi().create_repo(repo_name, exist_ok=True)\n",
    "\n",
    "# Upload the model\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=\"E:\\git_hub\\saved_fine_tuned_model\", \n",
    "    repo_id=\"kai-pn/\" + repo_name,  \n",
    "    repo_type=\"model\"\n",
    ")\n",
    "print(f\"Model uploaded to {repo_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Ok. not too excellent but acceptable for its cost.\n",
      "Predicted Sentiment: NEU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"kai-pn/sentiment-analysis-roberta\" \n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "texts = [\"Ok. not too excellent but acceptable for its cost.\"]\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():  \n",
    "    outputs = model(**inputs)  \n",
    "    predictions = outputs.logits.argmax(dim=-1)  \n",
    "\n",
    "label_mapping_reverse = {0: 'NEG', 1: 'NEU', 2: 'POS'}\n",
    "results = [label_mapping_reverse[pred.item()] for pred in predictions] \n",
    "\n",
    "for text, sentiment in zip(texts, results):\n",
    "    print(f\"Text: {text}\\nPredicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer successfully loaded from kai-pn/sentiment-analysis-roberta\n",
      "Model configured with 3 labels.\n",
      "Text: The product is excellent, works as expected!\n",
      "Predicted Sentiment: POS\n",
      "\n",
      "Text: Terrible experience, I want my money back.\n",
      "Predicted Sentiment: NEG\n",
      "\n",
      "Text: It's okay, not great but not bad either.\n",
      "Predicted Sentiment: NEU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_model_and_tokenizer(model_path='kai-pn/sentiment-analysis-roberta'):\n",
    "    try:\n",
    "        model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        print(f\"Model and tokenizer successfully loaded from {model_path}\")\n",
    "        print(f\"Model configured with {model.config.num_labels} labels.\")   \n",
    "\n",
    "        return model, tokenizer, device\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading model or tokenizer from {model_path}: {e}\")\n",
    "\n",
    "def predict(texts, model, tokenizer, device):\n",
    "    \"\"\"Predict sentiments for a list of texts.\"\"\"\n",
    "\n",
    "    inputs = tokenizer(texts, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()  # Move outputs to CPU for further processing\n",
    "    \n",
    "    label_mapping_reverse = {0: 'NEG', 1: 'NEU', 2: 'POS'}\n",
    "    return [label_mapping_reverse[pred] for pred in predictions]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer, device = load_model_and_tokenizer('kai-pn/sentiment-analysis-roberta')\n",
    "    \n",
    "    sample_texts = [\n",
    "        \"The product is excellent, works as expected!\",\n",
    "        \"Terrible experience, I want my money back.\",\n",
    "        \"It's okay, not great but not bad either.\"\n",
    "    ]\n",
    "    predictions = predict(sample_texts, model, tokenizer, device)\n",
    "    for text, label in zip(sample_texts, predictions):\n",
    "        print(f\"Text: {text}\\nPredicted Sentiment: {label}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
